{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "- TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acknowledgements**\n",
    "- Dataset: https://www.tensorflow.org/datasets/catalog/tf_flowers\n",
    "- Blog Article: https://rom1504.medium.com/image-embeddings-ed1b194d113e\n",
    "- Code Repo: https://github.com/rom1504/image_embeddings\n",
    "- Code File: https://github.com/rom1504/image_embeddings/blob/master/notebooks/from_scratch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as pkg_num\n",
    "import os as pkg_os\n",
    "import time as pkg_time\n",
    "import math as pkg_math\n",
    "import warnings as pkg_warnings\n",
    "import matplotlib.pyplot as pkg_mplot\n",
    "import matplotlib.image as pkg_mp_image\n",
    "import pathlib as pkg_pathlib\n",
    "import shutil as pkg_shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record Start Time\n",
    "run_start_time = pkg_time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous\n",
    "%matplotlib inline\n",
    "pkg_warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# Tensor Flow is optimized for CUDA-GPU\n",
    "# That error goes away with following setting\n",
    "# TODO: Figure out why the error goes away with this setting!\n",
    "pkg_os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl.logging as pkg_logging\n",
    "import IPython.display as pkg_disp\n",
    "import ipywidgets as pkg_widgets\n",
    "import PIL as pkg_pil\n",
    "import PIL.Image as pkg_pil_image\n",
    "import pyarrow as pkg_arrow\n",
    "import pyarrow.parquet as pkg_parquet\n",
    "import tensorflow as pkg_tf\n",
    "import tensorflow_datasets as pkg_tfds\n",
    "import tensorflow_datasets.core.dataset_utils as pkg_tfds_utils\n",
    "import tensorflow_datasets.core.features as pkg_tfds_features\n",
    "import efficientnet as pkg_effinet\n",
    "import efficientnet.preprocessing as pkg_effinet_preprocessing\n",
    "import efficientnet.tfkeras as pkg_tfkeras\n",
    "from efficientnet.tfkeras import EfficientNetB3 as EfficientNetRef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance related settings\n",
    "AUTOTUNE = pkg_tf.data.AUTOTUNE\n",
    "\n",
    "# Image Size (Target)\n",
    "image_height = 180\n",
    "image_width = 180\n",
    "image_size = (image_height, image_width)\n",
    "\n",
    "# Batch Size\n",
    "batch_size = 32\n",
    "\n",
    "# Path stuff\n",
    "repo_root_dirpath = pkg_pathlib.Path.cwd().parent\n",
    "temp_root_dirpath = repo_root_dirpath.joinpath(\".outputs\")\n",
    "temp_flowers_ds_dirpath = temp_root_dirpath.joinpath(\".datasets/tf_flowers\")\n",
    "\n",
    "folder_name_downloads = \"downloads\"\n",
    "temp_downloads_dirpath = temp_flowers_ds_dirpath.joinpath(folder_name_downloads)\n",
    "\n",
    "folder_name_images = \"images\"\n",
    "temp_images_dirpath = temp_flowers_ds_dirpath.joinpath(folder_name_images)\n",
    "\n",
    "folder_name_tfrecords = \"tfrecords\"\n",
    "temp_tfrecords_dirpath = temp_flowers_ds_dirpath.joinpath(folder_name_tfrecords)\n",
    "\n",
    "folder_name_embeddings = \"embeddings\"\n",
    "temp_embeddings_dirpath = temp_flowers_ds_dirpath.joinpath(folder_name_embeddings)\n",
    "\n",
    "temp_dirpaths = {\n",
    "    folder_name_downloads: temp_downloads_dirpath,\n",
    "    folder_name_images : temp_images_dirpath,\n",
    "    folder_name_tfrecords: temp_tfrecords_dirpath,\n",
    "    folder_name_embeddings : temp_embeddings_dirpath\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_batch_performance(ds):\n",
    "  ds = configure_for_performance(ds)\n",
    "  ds = ds.batch(batch_size=batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirpath(dirpath):\n",
    "    # Create the data directory\n",
    "    dirpath.mkdir(parents=True, exist_ok=True)\n",
    "    return dirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_dirpath(dirpath):\n",
    "    # (Re)create the data directory\n",
    "    pkg_shutil.rmtree(dirpath, ignore_errors=True)\n",
    "    dirpath.mkdir(parents=True, exist_ok=False)\n",
    "    return dirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_folder(folder_name):\n",
    "    return recreate_dirpath(temp_dirpaths[folder_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_folder_stats(folder_name):\n",
    "    checkpoint_time = int(pkg_time.time() - run_start_time)\n",
    "    print(\"Directory Stats ({}), at {} seconds: {}\".format(\\\n",
    "        folder_name, checkpoint_time, temp_dirpaths[folder_name].stat()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(dataset_name, data_dirpath):\n",
    "    ds, ds_info = pkg_tfds.load(name=dataset_name, data_dir=data_dirpath, \n",
    "        split='train', with_info=True)\n",
    "    return ds, ds_info\n",
    "\n",
    "def save_examples(ds, ds_info, data_dirpath, num_examples = 10, image_key=None):\n",
    "  \"\"\"Save images from an image classification dataset.\n",
    "\n",
    "  Only works with datasets that have 1 image feature and optionally 1 label\n",
    "  feature (both inferred from `ds_info`). Note the dataset should be unbatched.\n",
    "\n",
    "  Usage:\n",
    "\n",
    "  ```python\n",
    "  ds, ds_info = tfds.load('cifar10', split='train', with_info=True)\n",
    "  fig = save_examples(ds, ds_info, data_dir)\n",
    "  ```\n",
    "\n",
    "  Args:\n",
    "    ds: `tf.data.Dataset`. The tf.data.Dataset object to visualize. Examples\n",
    "      should not be batched.\n",
    "    num_examples: `int`. Number of examples to save\n",
    "    ds_info: The dataset info object to which extract the label and features\n",
    "      info. Available either through `tfds.load('mnist', with_info=True)` or\n",
    "      `tfds.builder('mnist').info`\n",
    "    data_dir: `pathlib.Path`. Where to save images\n",
    "    image_key: `string`, name of the feature that contains the image. If not\n",
    "       set, the system will try to auto-detect it.\n",
    "\n",
    "  Returns:\n",
    "  \"\"\"\n",
    "\n",
    "  if not image_key:\n",
    "    # Infer the image and label keys\n",
    "    image_keys = [\n",
    "        k for k, feature in ds_info.features.items()\n",
    "        if isinstance(feature, pkg_tfds_features.Image)\n",
    "    ]\n",
    "\n",
    "    if not image_keys:\n",
    "      raise ValueError(\n",
    "          \"Visualisation not supported for dataset `{}`. Was not able to \"\n",
    "          \"auto-infer image.\".format(ds_info.name))\n",
    "\n",
    "    if len(image_keys) > 1:\n",
    "      raise ValueError(\n",
    "          \"Multiple image features detected in the dataset. Using the first one. You can \"\n",
    "          \"use `image_key` argument to override. Images detected: %s\" %\n",
    "          (\",\".join(image_keys)))\n",
    "\n",
    "    image_key = image_keys[0]\n",
    "\n",
    "  label_keys = [\n",
    "      k for k, feature in ds_info.features.items()\n",
    "      if isinstance(feature, pkg_tfds_features.ClassLabel)\n",
    "  ]\n",
    "\n",
    "  label_key = label_keys[0] if len(label_keys) == 1 else None\n",
    "  if not label_key:\n",
    "    pkg_logging.info(\"Was not able to auto-infer label.\")\n",
    "\n",
    "  examples = list(pkg_tfds_utils.as_numpy(ds.take(num_examples)))\n",
    "  \n",
    "  # Save the images as files on disk\n",
    "  for i, ex in enumerate(examples):\n",
    "    if not isinstance(ex, dict):\n",
    "      raise ValueError(\n",
    "          \"tensorflow_datasets.show_examples requires examples as `dict`, with the same \"\n",
    "          \"structure as `ds_info.features`. It is currently not compatible \"\n",
    "          \"with `as_supervised=True`. Received: {}\".format(type(ex)))\n",
    "\n",
    "    # Plot the image\n",
    "    image = ex[image_key]\n",
    "    if len(image.shape) != 3:\n",
    "      raise ValueError(\n",
    "          \"Image dimension should be 3. tensorflow_datasets.show_examples does not support \"\n",
    "          \"batched examples or video.\")\n",
    "    _, _, c = image.shape\n",
    "    if c == 1:\n",
    "      image = image.reshape(image.shape[:2])\n",
    "    image = pkg_effinet_preprocessing.center_crop_and_resize(image, 224).astype(pkg_num.uint8)\n",
    "    im = pkg_pil_image.fromarray(image)\n",
    "    # Plot the label\n",
    "    if label_key:\n",
    "      label = ex[label_key]\n",
    "      label_str = ds_info.features[label_key].int2str(label)\n",
    "    else:\n",
    "      label_str = \"\"\n",
    "    filepath = data_dirpath.joinpath(\"image_{:04d}_{}.jpeg\".format(i, label_str))\n",
    "    im.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_save_flowers_dataset(example_count):\n",
    "    create_dirpath(temp_downloads_dirpath)\n",
    "    ds, ds_info = download_dataset(\"tf_flowers\", temp_downloads_dirpath)\n",
    "    print_folder_stats(folder_name_downloads)\n",
    "\n",
    "    recreate_dirpath(temp_images_dirpath)\n",
    "    save_examples(ds, ds_info, temp_images_dirpath, example_count)\n",
    "    print_folder_stats(folder_name_images)\n",
    "\n",
    "    ds = configure_for_performance(ds)\n",
    "    fig = pkg_tfds.show_examples(ds, ds_info)\n",
    "    return ds, ds_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Routines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(folder_name, pattern=\"*\", shuffle=False):\n",
    "    dirpath = temp_dirpaths[folder_name].as_posix()\n",
    "    return pkg_tf.data.Dataset.list_files(dirpath + \"/\" + pattern, shuffle=shuffle)\n",
    "\n",
    "def process_path(file_path):\n",
    "    parts = pkg_tf.strings.split(file_path, '/')\n",
    "    image_name = pkg_tf.strings.split(parts[-1], '.')[0]\n",
    "    raw = pkg_tf.io.read_file(file_path)\n",
    "    return raw, image_name\n",
    "\n",
    "\n",
    "def read_data_from_files(list_ds):\n",
    "    return list_ds.map(process_path,\n",
    "        num_parallel_calls=pkg_tf.data.experimental.AUTOTUNE)#.apply(pkg_tf.data.experimental.ignore_errors())\n",
    "\n",
    "\n",
    "def images_to_embeddings(model, dataset, batch_size):\n",
    "    return model.predict(dataset.batch(batch_size).map(lambda image_raw, image_name: image_raw), verbose=1)\n",
    "\n",
    "\n",
    "def save_embeddings_ds_to_parquet(embeddings, dataset, path):\n",
    "    embeddings = pkg_arrow.array(embeddings.tolist(), type=pkg_arrow.list_(pkg_arrow.float32()))\n",
    "    image_names = pkg_arrow.array(dataset.map(lambda image_raw, image_name: image_name).as_numpy_iterator())\n",
    "    table = pkg_arrow.Table.from_arrays([image_names, embeddings], [\"image_name\", \"embedding\"])\n",
    "    pkg_parquet.write_table(table, path)\n",
    "\n",
    "\n",
    "def compute_save_embeddings(input_folder_name, output_folder_name, num_shards, model, batch_size):\n",
    "    start = pkg_time.time()\n",
    "    list_ds = list_files(input_folder_name, \"*.jpeg\").cache()\n",
    "\n",
    "    output_dirpath = temp_dirpaths[output_folder_name]\n",
    "    for shard_id in range(0, num_shards):\n",
    "        shard_list = list_ds.shard(num_shards=num_shards, index=shard_id)\n",
    "        shard = read_data_from_files(shard_list)\n",
    "        embeddings = images_to_embeddings(model, shard, batch_size)\n",
    "        print(\"Shard \" + str(shard_id) + \" done after \" + str(int(pkg_time.time() - start)) + \"s\")\n",
    "        output_filepath = output_dirpath.joinpath(\"part-{:04d}.parquet\".format(shard_id))\n",
    "        save_embeddings_ds_to_parquet(embeddings, shard, output_filepath)\n",
    "        print(\"Shard \" + str(shard_id) + \" saved after \" + str(int(pkg_time.time() - start)) + \"s\")\n",
    "    print(\"Total time : \" + str(int(pkg_time.time() - start)))\n",
    "\n",
    "\n",
    "def infer_images(input_folder_name, output_folder_name, num_shards=100, batch_size=1000):\n",
    "    model = EfficientNetRef(weights='imagenet', include_top=False, pooling=\"avg\")\n",
    "    compute_save_embeddings(input_folder_name, output_folder_name, num_shards, model, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return pkg_tf.train.Feature(int64_list=pkg_tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(pkg_tf.constant(0))):\n",
    "        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n",
    "    return pkg_tf.train.Feature(bytes_list=pkg_tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def serialize_example(image, image_name):\n",
    "    feature = {\n",
    "        'image_name': _bytes_feature(image_name),\n",
    "        'image_data': _bytes_feature(image)\n",
    "    }\n",
    "\n",
    "    example_proto = pkg_tf.train.Example(features=pkg_tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "\n",
    "def tf_serialize_example(image, image_name):\n",
    "    tf_string = pkg_tf.py_function(\n",
    "        serialize_example,\n",
    "        (image, image_name),\n",
    "        pkg_tf.string)\n",
    "    return pkg_tf.reshape(tf_string, ())\n",
    "\n",
    "\n",
    "def process_path(file_path):\n",
    "    parts = pkg_tf.strings.split(file_path, '/')\n",
    "    image_name = pkg_tf.strings.split(parts[-1], '.')[0]\n",
    "    raw = pkg_tf.io.read_file(file_path)\n",
    "    return raw, image_name\n",
    "\n",
    "\n",
    "def read_image_file_write_tfrecord(files_ds, output_filepath):\n",
    "    image_ds = files_ds.map(process_path, num_parallel_calls=pkg_tf.data.experimental.AUTOTUNE)\n",
    "    serialized_features_dataset = image_ds.map(tf_serialize_example, num_parallel_calls=pkg_tf.data.experimental.AUTOTUNE)\n",
    "    writer = pkg_tf.data.experimental.TFRecordWriter(output_filepath.as_posix())\n",
    "    writer.write(serialized_features_dataset)\n",
    "\n",
    "\n",
    "def image_files_to_tfrecords(image_folder_name, output_folder_name, num_shard):\n",
    "    list_ds = list_files(image_folder_name, \"*.jpeg\")\n",
    "    output_dirpath = temp_dirpaths[output_folder_name]\n",
    "    start = pkg_time.time()\n",
    "    for shard_id in range(0, num_shard):\n",
    "        shard_list = list_ds.shard(num_shards=num_shard, index=shard_id)\n",
    "        output_filepath = output_dirpath.joinpath(\"part-{:04d}.tfrecord\".format(shard_id))\n",
    "        read_image_file_write_tfrecord(shard_list, output_filepath)\n",
    "        print(\"Shard \" + str(shard_id) + \" saved after \" + str(int(pkg_time.time() - start)) + \"s\")\n",
    "\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'image_name': pkg_tf.io.FixedLenFeature([], pkg_tf.string),\n",
    "        'image_data': pkg_tf.io.FixedLenFeature([], pkg_tf.string)\n",
    "    }\n",
    "    return pkg_tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "\n",
    "def preprocess_image(d):\n",
    "    image_name = d['image_name']\n",
    "    raw = d['image_data']\n",
    "    image = pkg_tf.image.decode_jpeg(raw)\n",
    "    image = pkg_tf.image.convert_image_dtype(image, pkg_tf.float32)\n",
    "\n",
    "    return image, image_name\n",
    "\n",
    "\n",
    "def read_tfrecord(filepath):\n",
    "    raw_dataset =  pkg_tf.data.TFRecordDataset(filenames=[filepath])\n",
    "    return raw_dataset \\\n",
    "        .map(_parse_function, num_parallel_calls=pkg_tf.data.experimental.AUTOTUNE) \\\n",
    "        .map(preprocess_image, num_parallel_calls=pkg_tf.data.experimental.AUTOTUNE) \\\n",
    "        .apply(pkg_tf.data.experimental.ignore_errors())\n",
    "\n",
    "\n",
    "def tfrecords_to_embeddings(input_folder_name, output_folder_name, model, batch_size):\n",
    "    tfrecords = [f.numpy().decode(\"utf-8\") for f in list_files(input_folder_name, \"*.tfrecord\")]\n",
    "    start = pkg_time.time()\n",
    "    output_dirpath = temp_dirpaths[output_folder_name]\n",
    "    for shard_id, tfrecord in enumerate(tfrecords):\n",
    "        shard = read_tfrecord(tfrecord)\n",
    "        embeddings = images_to_embeddings(model, shard, batch_size)\n",
    "        print(\"Shard \" + str(shard_id) + \" done after \" + str(int(pkg_time.time() - start)) + \"s\")\n",
    "        output_filepath = output_dirpath.joinpath(\"part-{:04d}.parquet\".format(shard_id))\n",
    "        save_embeddings_ds_to_parquet(embeddings, shard, output_filepath)\n",
    "        print(\"Shard \" + str(shard_id) + \" saved after \" + str(int(pkg_time.time() - start)) + \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_embeddings_flowers_dataset(shard_count):\n",
    "    recreate_folder(folder_name_tfrecords)\n",
    "    image_files_to_tfrecords(folder_name_images, folder_name_tfrecords, shard_count)\n",
    "    print_folder_stats(folder_name_tfrecords)\n",
    "\n",
    "    recreate_folder(folder_name_embeddings)\n",
    "    model = EfficientNetRef(weights='imagenet', include_top=False, pooling=\"avg\")\n",
    "    tfrecords_to_embeddings(folder_name_tfrecords, folder_name_embeddings, model, batch_size)\n",
    "    print_folder_stats(folder_name_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard 0 saved after 0s\n",
      "Shard 1 saved after 0s\n",
      "Shard 2 saved after 0s\n",
      "Shard 3 saved after 1s\n",
      "Shard 4 saved after 1s\n",
      "Shard 5 saved after 1s\n",
      "Shard 6 saved after 2s\n",
      "Shard 7 saved after 2s\n",
      "Shard 8 saved after 3s\n",
      "Shard 9 saved after 3s\n",
      "Directory Stats (tfrecords), at 4 seconds: os.stat_result(st_mode=16877, st_ino=354770, st_dev=2112, st_nlink=2, st_uid=1000, st_gid=1000, st_size=4096, st_atime=1661145292, st_mtime=1661145295, st_ctime=1661145295)\n",
      "7/7 [==============================] - 15s 2s/step\n",
      "Shard 0 done after 15s\n",
      "Shard 0 saved after 15s\n",
      "7/7 [==============================] - 12s 2s/step\n",
      "Shard 1 done after 27s\n",
      "Shard 1 saved after 27s\n",
      "7/7 [==============================] - 11s 2s/step\n",
      "Shard 2 done after 39s\n",
      "Shard 2 saved after 39s\n",
      "7/7 [==============================] - 12s 2s/step\n",
      "Shard 3 done after 52s\n",
      "Shard 3 saved after 52s\n",
      "7/7 [==============================] - 12s 2s/step\n",
      "Shard 4 done after 64s\n",
      "Shard 4 saved after 64s\n",
      "7/7 [==============================] - 11s 2s/step\n",
      "Shard 5 done after 76s\n",
      "Shard 5 saved after 76s\n",
      "7/7 [==============================] - 11s 2s/step\n",
      "Shard 6 done after 87s\n",
      "Shard 6 saved after 88s\n",
      "7/7 [==============================] - 12s 2s/step\n",
      "Shard 7 done after 100s\n",
      "Shard 7 saved after 100s\n",
      "7/7 [==============================] - 12s 2s/step\n",
      "Shard 8 done after 112s\n",
      "Shard 8 saved after 113s\n",
      "7/7 [==============================] - 11s 2s/step\n",
      "Shard 9 done after 124s\n",
      "Shard 9 saved after 124s\n",
      "Directory Stats (embeddings), at 132 seconds: os.stat_result(st_mode=16877, st_ino=358595, st_dev=2112, st_nlink=2, st_uid=1000, st_gid=1000, st_size=4096, st_atime=1661145295, st_mtime=1661145423, st_ctime=1661145423)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Uncomment the below on a fresh machine\n",
    "# Once downloaded and saved, comment it back\n",
    "# Once run, we can use the same data for all the runs\n",
    "#download_and_save_flowers_dataset(example_count=2000)\n",
    "\n",
    "calculate_and_save_embeddings_flowers_dataset(shard_count = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Run Time: 132 seconds\n"
     ]
    }
   ],
   "source": [
    "# Compute Total Run Time\n",
    "run_time_seconds = int(pkg_time.time() - run_start_time)\n",
    "print(\"Total Run Time: {} seconds\".format(run_time_seconds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
