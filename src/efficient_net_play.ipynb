{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Embeddings using EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "- Frameworks: Tensor Flow and FAISS\n",
    "- Area: Image Embeddings\n",
    "- Pre-Trained Model: EfficientNet\n",
    "- Algorithms: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acknowledgements**\n",
    "- Blog Article: https://rom1504.medium.com/image-embeddings-ed1b194d113e\n",
    "- Code File: https://colab.research.google.com/github/rom1504/image_embeddings/blob/master/notebooks/using_the_lib.ipynb\n",
    "- Code Repo: https://github.com/rom1504/image_embeddings\n",
    "- Code File: https://github.com/rom1504/image_embeddings/blob/master/notebooks/from_scratch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization: Download and Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as pkg_num\n",
    "import os as pkg_os\n",
    "import time as pkg_time\n",
    "import math as pkg_math\n",
    "import random as pkg_random\n",
    "import warnings as pkg_warnings\n",
    "import matplotlib.pyplot as pkg_mplot\n",
    "import matplotlib.image as pkg_mp_image\n",
    "import pathlib as pkg_pathlib\n",
    "import shutil as pkg_shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Start Time\n",
    "run_start_time = pkg_time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous\n",
    "%matplotlib inline\n",
    "\n",
    "# Tensor Flow is optimized for CUDA-GPU, \n",
    "# But we are running on a different GPU or simply CPU, so ignore warnings\n",
    "pkg_warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# OpenMP library may be linked and loaded multiple times due to transitive dependencies\n",
    "# Informed that multiple instances of OpenMP library is OK for us\n",
    "# That error goes away with following setting\n",
    "pkg_os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pkg_pandas\n",
    "import absl.logging as pkg_logging\n",
    "import IPython.display as pkg_disp\n",
    "import ipywidgets as pkg_widgets\n",
    "import PIL as pkg_pil\n",
    "import PIL.Image as pkg_pil_image\n",
    "import pyarrow as pkg_arrow\n",
    "import pyarrow.parquet as pkg_parquet\n",
    "import tensorflow as pkg_tf\n",
    "import tensorflow_datasets as pkg_tfds\n",
    "import tensorflow_datasets.core.dataset_utils as pkg_tfds_utils\n",
    "import tensorflow_datasets.core.features as pkg_tfds_features\n",
    "import efficientnet as pkg_effinet\n",
    "import efficientnet.preprocessing as pkg_effinet_preprocessing\n",
    "import efficientnet.tfkeras as pkg_tfkeras\n",
    "from efficientnet.tfkeras import EfficientNetB6 as EfficientNetRef\n",
    "import faiss as pkg_faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance related settings\n",
    "AUTOTUNE = pkg_tf.data.AUTOTUNE\n",
    "\n",
    "# Image Size (Target)\n",
    "image_height = 180\n",
    "image_width = 180\n",
    "image_size = (image_height, image_width)\n",
    "\n",
    "# Path stuff\n",
    "repo_root_dirpath = pkg_pathlib.Path.cwd().parent\n",
    "temp_root_dirpath = repo_root_dirpath.joinpath(\".outputs/.datasets\")\n",
    "data_root_dirpath = repo_root_dirpath.joinpath(\"data/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds\n",
    "\n",
    "def configure_for_batch_performance(ds,batch_size):\n",
    "  ds = configure_for_performance(ds)\n",
    "  ds = ds.batch(batch_size=batch_size)\n",
    "  return ds\n",
    "\n",
    "def create_dirpath(dirpath):\n",
    "  # Create the data directory\n",
    "  dirpath.mkdir(parents=True, exist_ok=True)\n",
    "  return dirpath\n",
    "\n",
    "def recreate_dirpath(dirpath):\n",
    "  # (Re)create the data directory\n",
    "  pkg_shutil.rmtree(dirpath, ignore_errors=True)\n",
    "  dirpath.mkdir(parents=True, exist_ok=False)\n",
    "  return dirpath\n",
    "\n",
    "def print_dirpath_stats(dirpath):\n",
    "  checkpoint_time = int(pkg_time.time() - run_start_time)\n",
    "  print(\"Directory Stats ({}), at {} seconds: {}\".format(\\\n",
    "    dirpath.name, checkpoint_time, dirpath.stat()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(dataset_name, data_dirpath):\n",
    "    ds, ds_info = pkg_tfds.load(name=dataset_name, data_dir=data_dirpath, \n",
    "        split='train', with_info=True)\n",
    "    return ds, ds_info\n",
    "\n",
    "def save_examples(ds, ds_info, data_dirpath, num_examples = 10, image_key=None):\n",
    "  \"\"\"Save images from an image classification dataset.\n",
    "\n",
    "  Only works with datasets that have 1 image feature and optionally 1 label\n",
    "  feature (both inferred from `ds_info`). Note the dataset should be unbatched.\n",
    "\n",
    "  Usage:\n",
    "\n",
    "  ```python\n",
    "  ds, ds_info = tfds.load('cifar10', split='train', with_info=True)\n",
    "  fig = save_examples(ds, ds_info, data_dir)\n",
    "  ```\n",
    "\n",
    "  Args:\n",
    "    ds: `tf.data.Dataset`. The tf.data.Dataset object to visualize. Examples\n",
    "      should not be batched.\n",
    "    num_examples: `int`. Number of examples to save\n",
    "    ds_info: The dataset info object to which extract the label and features\n",
    "      info. Available either through `tfds.load('mnist', with_info=True)` or\n",
    "      `tfds.builder('mnist').info`\n",
    "    data_dir: `pathlib.Path`. Where to save images\n",
    "    image_key: `string`, name of the feature that contains the image. If not\n",
    "       set, the system will try to auto-detect it.\n",
    "\n",
    "  Returns:\n",
    "  \"\"\"\n",
    "\n",
    "  if not image_key:\n",
    "    # Infer the image and label keys\n",
    "    image_keys = [\n",
    "        k for k, feature in ds_info.features.items()\n",
    "        if isinstance(feature, pkg_tfds_features.Image)\n",
    "    ]\n",
    "\n",
    "    if not image_keys:\n",
    "      raise ValueError(\n",
    "          \"Visualisation not supported for dataset `{}`. Was not able to \"\n",
    "          \"auto-infer image.\".format(ds_info.name))\n",
    "\n",
    "    if len(image_keys) > 1:\n",
    "      raise ValueError(\n",
    "          \"Multiple image features detected in the dataset. Using the first one. You can \"\n",
    "          \"use `image_key` argument to override. Images detected: %s\" %\n",
    "          (\",\".join(image_keys)))\n",
    "\n",
    "    image_key = image_keys[0]\n",
    "\n",
    "  label_keys = [\n",
    "      k for k, feature in ds_info.features.items()\n",
    "      if isinstance(feature, pkg_tfds_features.ClassLabel)\n",
    "  ]\n",
    "\n",
    "  label_key = label_keys[0] if len(label_keys) == 1 else None\n",
    "  if not label_key:\n",
    "    pkg_logging.info(\"Was not able to auto-infer label.\")\n",
    "\n",
    "  examples = list(pkg_tfds_utils.as_numpy(ds.take(num_examples)))\n",
    "  \n",
    "  # Save the images as files on disk\n",
    "  for i, ex in enumerate(examples):\n",
    "    if not isinstance(ex, dict):\n",
    "      raise ValueError(\n",
    "          \"tensorflow_datasets.show_examples requires examples as `dict`, with the same \"\n",
    "          \"structure as `ds_info.features`. It is currently not compatible \"\n",
    "          \"with `as_supervised=True`. Received: {}\".format(type(ex)))\n",
    "\n",
    "    # Plot the image\n",
    "    image = ex[image_key]\n",
    "    if len(image.shape) != 3:\n",
    "      raise ValueError(\n",
    "          \"Image dimension should be 3. tensorflow_datasets.show_examples does not support \"\n",
    "          \"batched examples or video.\")\n",
    "    _, _, c = image.shape\n",
    "    if c == 1:\n",
    "      image = image.reshape(image.shape[:2])\n",
    "    image = pkg_effinet_preprocessing.center_crop_and_resize(image, 224).astype(pkg_num.uint8)\n",
    "    im = pkg_pil_image.fromarray(image)\n",
    "    # Plot the label\n",
    "    if label_key:\n",
    "      label = ex[label_key]\n",
    "      label_str = ds_info.features[label_key].int2str(label)\n",
    "    else:\n",
    "      label_str = \"\"\n",
    "    filepath = data_dirpath.joinpath(\"image_{:04d}_{}.jpeg\".format(i, label_str))\n",
    "    im.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_save_dataset(dataset_name, downloads_dirpath, example_count, images_dirpath):\n",
    "    create_dirpath(downloads_dirpath)\n",
    "    ds, ds_info = download_dataset(dataset_name=dataset_name, data_dirpath=downloads_dirpath)\n",
    "    print_dirpath_stats(downloads_dirpath)\n",
    "\n",
    "    recreate_dirpath(images_dirpath)\n",
    "    save_examples(ds, ds_info, images_dirpath, example_count)\n",
    "    print_dirpath_stats(images_dirpath)\n",
    "\n",
    "    ds = configure_for_performance(ds)\n",
    "    fig = pkg_tfds.show_examples(ds, ds_info)\n",
    "    return ds, ds_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform: Calculate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Routines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dirpath(dirpath, pattern=\"*\", shuffle=False):\n",
    "    return pkg_tf.data.Dataset.list_files(dirpath.as_posix() + \"/\" + pattern, shuffle=shuffle)\n",
    "\n",
    "def load_image(filepath):\n",
    "    image_name = filepath.stem\n",
    "    image_data = pkg_tf.io.read_file(filepath.as_posix())\n",
    "    return image_name, image_data\n",
    "\n",
    "def read_data_from_files(list_ds):\n",
    "    return list_ds.map(load_image,\n",
    "        num_parallel_calls=pkg_tf.data.experimental.AUTOTUNE)#.apply(pkg_tf.data.experimental.ignore_errors())\n",
    "\n",
    "def images_to_embeddings(model, dataset, batch_size):\n",
    "    return model.predict(dataset.batch(batch_size).map(lambda image_name, image_data: image_data), verbose=1)\n",
    "\n",
    "def save_embeddings_ds_to_parquet(embeddings, dataset, path):\n",
    "    embeddings = pkg_arrow.array(embeddings.tolist(), type=pkg_arrow.list_(pkg_arrow.float32()))\n",
    "    image_names = pkg_arrow.array(dataset.map(lambda image_name, image_data: image_name).as_numpy_iterator())\n",
    "    table = pkg_arrow.Table.from_arrays([image_names, embeddings], [\"image_name\", \"embedding\"])\n",
    "    pkg_parquet.write_table(table, path)\n",
    "\n",
    "def compute_save_embeddings(image_dirpath, embeddings_dirpath, num_shards, model, batch_size):\n",
    "    start = pkg_time.time()\n",
    "    list_ds = list_dirpath(image_dirpath, \"*.jpeg\").cache()\n",
    "\n",
    "    for shard_id in range(0, num_shards):\n",
    "        shard_list = list_ds.shard(num_shards=num_shards, index=shard_id)\n",
    "        shard = read_data_from_files(shard_list)\n",
    "        embeddings = images_to_embeddings(model, shard, batch_size)\n",
    "        print(\"Shard \" + str(shard_id) + \" done after \" + str(int(pkg_time.time() - start)) + \"s\")\n",
    "        embeddings_filepath = embeddings_dirpath.joinpath(\"part-{:04d}.parquet\".format(shard_id))\n",
    "        save_embeddings_ds_to_parquet(embeddings, shard, embeddings_filepath)\n",
    "        print(\"Shard \" + str(shard_id) + \" saved after \" + str(int(pkg_time.time() - start)) + \"s\")\n",
    "    print(\"Total time : \" + str(int(pkg_time.time() - start)))\n",
    "\n",
    "def infer_images(input_folder_name, output_folder_name, num_shards=100, batch_size=1000):\n",
    "    model = EfficientNetRef(weights='imagenet', include_top=False, pooling=\"avg\")\n",
    "    compute_save_embeddings(input_folder_name, output_folder_name, num_shards, model, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return pkg_tf.train.Feature(int64_list=pkg_tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(pkg_tf.constant(0))):\n",
    "        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n",
    "    return pkg_tf.train.Feature(bytes_list=pkg_tf.train.BytesList(value=[value]))\n",
    "\n",
    "def serialize_example(image_name, image_data):\n",
    "    feature = {\n",
    "        'image_name': _bytes_feature(image_name),\n",
    "        'image_data': _bytes_feature(image_data)\n",
    "    }\n",
    "\n",
    "    example_proto = pkg_tf.train.Example(features=pkg_tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "def tf_serialize_example(image_name, image_data):\n",
    "    tf_string = pkg_tf.py_function(\n",
    "        serialize_example,\n",
    "        (image_name, image_data),\n",
    "        pkg_tf.string)\n",
    "    return pkg_tf.reshape(tf_string, ())\n",
    "\n",
    "def load_image_tf(file_path):\n",
    "    parts = pkg_tf.strings.split(file_path, '/')\n",
    "    image_name = pkg_tf.strings.split(parts[-1], '.')[0]\n",
    "    image_data = pkg_tf.io.read_file(file_path)\n",
    "    return image_name, image_data\n",
    "\n",
    "def read_image_file_write_tfrecord(files_ds, output_filepath):\n",
    "    image_ds = files_ds.map(load_image_tf, num_parallel_calls=pkg_tf.data.experimental.AUTOTUNE)\n",
    "    serialized_features_dataset = image_ds.map(tf_serialize_example, num_parallel_calls=pkg_tf.data.experimental.AUTOTUNE)\n",
    "    writer = pkg_tf.data.experimental.TFRecordWriter(output_filepath.as_posix())\n",
    "    writer.write(serialized_features_dataset)\n",
    "\n",
    "def image_files_to_tfrecords(images_dirpath, tfrecords_dirpath, num_shard):\n",
    "    list_ds = list_dirpath(images_dirpath, \"*.jpeg\")\n",
    "    print(list_ds)\n",
    "    start = pkg_time.time()\n",
    "    for shard_id in range(0, num_shard):\n",
    "        shard_list = list_ds.shard(num_shards=num_shard, index=shard_id)\n",
    "        tfrecords_filepath = tfrecords_dirpath.joinpath(\"part-{:04d}.tfrecord\".format(shard_id))\n",
    "        read_image_file_write_tfrecord(shard_list, tfrecords_filepath)\n",
    "        print(\"Shard \" + str(shard_id) + \" saved after \" + str(int(pkg_time.time() - start)) + \"s\")\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'image_name': pkg_tf.io.FixedLenFeature([], pkg_tf.string),\n",
    "        'image_data': pkg_tf.io.FixedLenFeature([], pkg_tf.string)\n",
    "    }\n",
    "    return pkg_tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "def preprocess_image(d):\n",
    "    image_name = d['image_name']\n",
    "    image_data = d['image_data']\n",
    "    image_data = pkg_tf.image.decode_jpeg(image_data)\n",
    "    image_data = pkg_tf.image.convert_image_dtype(image_data, pkg_tf.float32)\n",
    "\n",
    "    return image_name, image_data\n",
    "\n",
    "def read_tfrecord(filepath):\n",
    "    raw_dataset =  pkg_tf.data.TFRecordDataset(filenames=[filepath])\n",
    "    return raw_dataset \\\n",
    "        .map(_parse_function, num_parallel_calls=pkg_tf.data.experimental.AUTOTUNE) \\\n",
    "        .map(preprocess_image, num_parallel_calls=pkg_tf.data.experimental.AUTOTUNE) \\\n",
    "        .apply(pkg_tf.data.experimental.ignore_errors())\n",
    "\n",
    "def tfrecords_to_embeddings(tfrecords_dirpath, embeddings_dirpath, model, batch_size):\n",
    "    tfrecords = [f.numpy().decode(\"utf-8\") for f in list_dirpath(tfrecords_dirpath, \"*.tfrecord\")]\n",
    "    start = pkg_time.time()\n",
    "    for shard_id, tfrecord in enumerate(tfrecords):\n",
    "        shard = read_tfrecord(tfrecord)\n",
    "        embeddings = images_to_embeddings(model, shard, batch_size)\n",
    "        print(\"Shard \" + str(shard_id) + \" done after \" + str(int(pkg_time.time() - start)) + \"s\")\n",
    "        embeddings_filepath = embeddings_dirpath.joinpath(\"part-{:04d}.parquet\".format(shard_id))\n",
    "        save_embeddings_ds_to_parquet(embeddings, shard, embeddings_filepath)\n",
    "        print(\"Shard \" + str(shard_id) + \" saved after \" + str(int(pkg_time.time() - start)) + \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_embeddings(model, images_dirpath, tfrecords_dirpath, embeddings_dirpath, shard_count, batch_size):\n",
    "    recreate_dirpath(tfrecords_dirpath)\n",
    "    image_files_to_tfrecords(images_dirpath, tfrecords_dirpath, shard_count)\n",
    "    print_dirpath_stats(tfrecords_dirpath)\n",
    "\n",
    "    recreate_dirpath(embeddings_dirpath)\n",
    "    tfrecords_to_embeddings(tfrecords_dirpath, embeddings_dirpath, model, batch_size)\n",
    "    print_dirpath_stats(embeddings_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_filepath(images_dirpath, image_name):\n",
    "  return images_dirpath.joinpath(image_name+\".jpeg\")\n",
    "\n",
    "def display_picture(image_filepath):\n",
    "  print(\"\\nQuery Image: {}\\n\".format(image_filepath.stem))\n",
    "  pkg_disp.display(pkg_disp.Image(filename=image_filepath, height=image_height, width=image_width))\n",
    "\n",
    "def display_picture_of_directory(images_dirpath, image_name):\n",
    "  display_picture(get_image_filepath(images_dirpath, image_name))\n",
    "\n",
    "def display_results(images_dirpath, results):\n",
    "  hbox = pkg_widgets.HBox([pkg_widgets.VBox([\n",
    "    pkg_widgets.widgets.Label(f\"{distance:.2f} {image_name}\"),\n",
    "    pkg_widgets.widgets.Image(value=open(get_image_filepath(images_dirpath, image_name), 'rb').read())\n",
    "  ]) for distance, image_name in results])\n",
    "  print(\"\\nResut Images: \\n\")\n",
    "  pkg_disp.display(hbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_into_dataframe(embeddings_dirpath):\n",
    "  file_list = [f.numpy().decode(\"utf-8\") for f in list_dirpath(embeddings_dirpath, \"*.parquet\")]\n",
    "  all_df = None\n",
    "  for file_path in file_list:\n",
    "    shard_df = pkg_parquet.read_table(file_path).to_pandas()\n",
    "    if (all_df is None): \n",
    "      all_df = shard_df\n",
    "    else:\n",
    "      all_df = pkg_pandas.concat([all_df, shard_df])\n",
    "  return all_df\n",
    "\n",
    "def populate_index(embeds):\n",
    "  num_dimensions = embeds.shape[1]\n",
    "  index = pkg_faiss.IndexFlatIP(num_dimensions)\n",
    "  index.add(embeds)\n",
    "  return index\n",
    "\n",
    "def build_maps(df):\n",
    "  id_to_name = {k:v.decode(\"utf-8\") for k,v in enumerate(list(df[\"image_name\"]))}\n",
    "  #name_to_id = {v:k for k,v in id_to_name.items()}\n",
    "  return id_to_name#, name_to_id\n",
    "\n",
    "def build_index_from_embeddings(embeddings_dirpath):\n",
    "  embed_df = load_embeddings_into_dataframe(embeddings_dirpath)\n",
    "  #print(embed_df.head())\n",
    "\n",
    "  embeds = pkg_num.stack(embed_df[\"embedding\"].to_numpy())\n",
    "  print(\"Shapes: DataFrame = {}, Embeddings = {}\".format(embed_df.shape, embeds.shape))\n",
    "\n",
    "  index = populate_index(embeds)\n",
    "\n",
    "  id_map = build_maps(embed_df)\n",
    "  print(\"Map Sizes: id_map = {}\".format(len(id_map)))\n",
    "\n",
    "  return index, embed_df, id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search_index(dataset_name, model, example_count, shard_count, batch_size,\n",
    "  should_download=False, should_compute_embeddings=False):\n",
    "  \n",
    "  temp_dataset_dirpath = temp_root_dirpath.joinpath(dataset_name)\n",
    "  temp_downloads_dirpath = temp_dataset_dirpath.joinpath(\"downloads\")\n",
    "  temp_images_dirpath = temp_dataset_dirpath.joinpath(\"images\")\n",
    "  temp_tfrecords_dirpath = temp_dataset_dirpath.joinpath(\"tfrecords\")\n",
    "  temp_embeddings_dirpath = temp_dataset_dirpath.joinpath(\"embeddings\")\n",
    "\n",
    "  # Once downloaded and saved, same can be reused for all the future runs\n",
    "  # By passing should_download=True, caller can retrigger download of dataset\n",
    "  if (should_download):\n",
    "    download_and_save_dataset(\n",
    "      downloads_dirpath=temp_downloads_dirpath, images_dirpath=temp_images_dirpath, \n",
    "      dataset_name=dataset_name, example_count=example_count)\n",
    "\n",
    "  # Once embeddings are calculated for a selected model, same can be reused for all the future runs\n",
    "  # By passing should_compute_embeddings=True, caller can retrigger computation of embeddings\n",
    "  if (should_download or should_compute_embeddings):\n",
    "    calculate_and_save_embeddings(model=model, images_dirpath=temp_images_dirpath, \n",
    "      tfrecords_dirpath=temp_tfrecords_dirpath, embeddings_dirpath=temp_embeddings_dirpath,\n",
    "      shard_count=shard_count, batch_size=batch_size)\n",
    "\n",
    "  index, embed_df, id_map = build_index_from_embeddings(embeddings_dirpath=temp_embeddings_dirpath)\n",
    "  return index, embed_df, temp_images_dirpath, id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_embeddings(model, dataset_name, images_dirpath, shard_count, \n",
    "  batch_size, should_compute_embeddings=False):\n",
    "\n",
    "  temp_testdata_dirpath = temp_root_dirpath.joinpath(dataset_name + \"_test\")\n",
    "  temp_tfrecords_dirpath = temp_testdata_dirpath.joinpath(\"tfrecords\")\n",
    "  temp_embeddings_dirpath = temp_testdata_dirpath.joinpath(\"embeddings\")\n",
    "\n",
    "  if (should_compute_embeddings):\n",
    "    calculate_and_save_embeddings(model=model, images_dirpath=images_dirpath, \n",
    "      tfrecords_dirpath=temp_tfrecords_dirpath, embeddings_dirpath=temp_embeddings_dirpath,\n",
    "      shard_count=shard_count, batch_size=batch_size)\n",
    "\n",
    "  embed_df = load_embeddings_into_dataframe(embeddings_dirpath=temp_embeddings_dirpath)\n",
    "  print(\"Shapes: DataFrame = {}\".format(embed_df.shape))\n",
    "\n",
    "  id_map = build_maps(embed_df)\n",
    "  print(\"Map Sizes: id_map = {}\".format(len(id_map)))\n",
    "\n",
    "  return embed_df, id_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_images(index, id_map, image_embedding, k=5):\n",
    "  dim, id_list = index.search(pkg_num.expand_dims(image_embedding, 0), k)\n",
    "  return list(zip(dim[0], [id_map[x] for x in id_list[0]]))\n",
    "\n",
    "def search_and_display_existing(index, dataset_embed_df, dataset_id_map, \n",
    "  dataset_images_dirpath, existing_image_name, k=5):\n",
    "  display_picture_of_directory(dataset_images_dirpath, existing_image_name)\n",
    "  existing_image_df = dataset_embed_df[dataset_embed_df[\"image_name\"] == bytes(existing_image_name, \"utf-8\")]\n",
    "  image_embedding = existing_image_df[\"embedding\"].to_numpy()[0]\n",
    "  display_results(dataset_images_dirpath, search_similar_images(index, dataset_id_map, image_embedding, k))\n",
    "\n",
    "def search_and_display_test(index, dataset_images_dirpath, dataset_id_map, \n",
    "  test_images_dirpath, test_embed_df, test_image_name, k=5):\n",
    "  display_picture_of_directory(test_images_dirpath, test_image_name)\n",
    "  test_image_df = test_embed_df[test_embed_df[\"image_name\"] == bytes(test_image_name, \"utf-8\")]\n",
    "  image_embedding = test_image_df[\"embedding\"].to_numpy()[0]\n",
    "  display_results(dataset_images_dirpath, search_similar_images(index, dataset_id_map, image_embedding, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Misc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested Datasets\n",
    "tested_datasets = [\"tf_flowers\", \"stanford_dogs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "target_example_count = 2000\n",
    "target_shard_count = 10\n",
    "target_batch_size = min(int(target_example_count/target_example_count), 20)\n",
    "target_match_count = 5\n",
    "target_dataset_name = tested_datasets[1]\n",
    "\n",
    "model = EfficientNetRef(weights='imagenet', include_top=False, pooling=\"avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, dataset_embed_df, dataset_images_dirpath, dataset_id_map = build_search_index(\n",
    "  dataset_name=target_dataset_name, model=model, example_count=target_example_count, \n",
    "  shard_count=target_shard_count, batch_size=target_batch_size,\n",
    "  should_download=False, should_compute_embeddings=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dirpath = data_root_dirpath.joinpath(target_dataset_name)\n",
    "test_embed_df, test_id_map = load_test_embeddings(model=model, \n",
    "  dataset_name=target_dataset_name, images_dirpath=test_images_dirpath,\n",
    "  shard_count=target_shard_count, batch_size=target_batch_size,\n",
    "  should_compute_embeddings=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Match: Test Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_image_name in test_id_map.values():\n",
    "  search_and_display_test(index, dataset_images_dirpath, dataset_id_map, \n",
    "    test_images_dirpath, test_embed_df, test_image_name, target_match_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Match: Random Dataset Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_image_names = list(dataset_id_map.values())\n",
    "for _ in range(10):\n",
    "  ds_image_name = pkg_random.choice(ds_image_names)\n",
    "  search_and_display_existing(index, dataset_embed_df, dataset_id_map, \n",
    "    dataset_images_dirpath, ds_image_name, target_match_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Match: Select Dataset Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_image_ids = [\n",
    "  7,    31,   67,   107,  131,  167,  278,  343,  476,  555,\n",
    "  649,  761,  873,  966,  1234, 1376, 1524, 1711, 1857, 1970\n",
    "]\n",
    "\n",
    "for image_id in existing_image_ids:\n",
    "  search_and_display_existing(index, dataset_embed_df, dataset_id_map, \n",
    "    dataset_images_dirpath, dataset_id_map[image_id], target_match_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Total Run Time\n",
    "run_time_seconds = int(pkg_time.time() - run_start_time)\n",
    "print(\"Total Run Time: {} seconds\".format(run_time_seconds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
